```{r setup, include=FALSE, echo=FALSE}

options(htmltools.dir.version = FALSE)
options(digits = 2)

library(knitr)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
knitr::opts_chunk$set(comment = "")

print_file <- function(file) {
  cat(paste(readLines(file), "\n", sep=""), sep="")
}
extract_one_draw <- function(stanfit, chain = 1, iter = 1) {
  x <- get_inits(stanfit, iter = iter)
  x[[chain]]
}
library("arm")
library("rstan")
# options(mc.cores = parallel::detectCores(logical = FALSE))
# rstan_options(auto_write = TRUE)
```
# <i style="font-size: 110%; padding:1.5em 0 0 0; color:#990017;">Part 1:  Overview</i> {-}

# Introduction

## Bayesian Data Analysis

### Bayesian inference and Stan {-}

Bayesian inference is the ultimate statistical power tool.  You embed your data and unknowns in a probability model, and then you get a "posterior distribution" which you can use to make inferences and predictions about everything.

Until recently, a big challenge for applied Bayesian inference was computation:  converting the mathematical expression of the posterior distribution into specific inferences or predictions such as the posterior probability that some coefficient is positive, or a 90% predictive interval for some future outcome.  For even moderately large or complex problems, such quantities are expressed mathematically in terms of high-dimensional integrals with no closed-form expressions.

Over the past fifty years, though, a series of advances in computational statistics have allowed these intergrals to be computed using approximations and simulations.  The simulations use random numbers and are called "Monte Carlo methods," named after the city in Europe that is famous for its gambling casinos.  These methods were originally developed in the 1940s for aiding in large computations for the military, and in the 1980s it became clear how to apply them for general problems in Bayesian inference.

So:  since the 1970s--1980s, methods have been developed to perform approximate computations for Bayesian inferences that would otherwise require intractable intervals.  These approximations needed to be developed one model at a time.  In the 1990s--2000s, the WinBugs software was developed, which allowed automatic computation for a large class of Bayesian models.  WinBugs (and its successors, OpenBugs and Jags) can be slow, and starting in 2011 we developed Stan, which uses more efficient computations (Hamilton Monte Carlo, the no-U-turn sampler, and algorithmic autodifferentiation) so that automatic Bayesian computation can be applied to larger and more complex problems.

Where we stand now is that, for a fairly broad class of models and data of moderate size, we can transparently program our Bayesian models in Stan and perform inference automatically.  This represent the culmination of decades of work in compuational statistics, along with  corresponding decades of experience fitting and understanding these models.  (The challenge is not just fitting the model; it is also deciding what models to fit.)

Future work, by ourselves and others, will increase the speed and scalability of Stan in various ways, including more seamless implentation of parallel processing.

### Appealing features of Bayesian inference {-}

Here are some reasons we like to use Bayesian methods:

* Integration of data and prior information

* Quantification of uncertainty, including probabilistic predictions

* Ability to pipe inference directly into decision analysis

* Ability to handle uncertainty in large numbers of parameters

It is said that the most important aspect of a statistical analysis is not what you do with the data, it's what data you use.  A key advantage of modern statistical methods (including Bayesian methods but also various non-Bayesian or semi-Bayesian approaches in machine learning) is that they allow you to incorporate different sorts of information into your analysis.


### Some things that Bayesian inference and Stan can't do {-}

Bayesian inference does not solve all statistical problems, though.  One important class of problems where it is not currently possible to perform fully Bayesian inference is nonlinear classification and optimization with large datasets:  familiar examples include language processing, speech and image recognition, and those computer programs that play Go or ping-pong.  These problems are often attacked using Bayesian models, but the inferences used are typically only rough approximations to the mathematical Bayesian posterior distribution:  the required calculations are simply too involved, and the posterior distributions tend to be multimodal and essentially impossible to fully navigate using any existing algorithm.  Stan is not the best tool for these problems.  We do think, however, that Stan is the best tool for fitting continuous-parameter models that arise in many application areas, including astronomy, ecology, economic forecasting, earth science, insurance, public health, survey sampling, to just name a few.  See here for some case studies:  http://mc-stan.org/users/documentation/case-studies and here for some example models:  https://github.com/stan-dev/example-models/wiki

### Model checking, model improvement, and workflow {-}

In Bayesian inference we make a sort of deal with the devil:  we commit to a strong model, and from this we get strong inferences.  But, as the saying goes, with great power comes great responsibility.  We need to vigilantly _check_ the fit of our models, following this up with model _improvement_.  As a result, Bayesian workflow does not involve fitting just one model to data.  We typically fit multiple models, including some models that we know are too simple (to get a sense of what is lost by not including certain features in our analysis) and others that we suspect are too complex (to get a sense of the boundaries of what we can learn given the resolution of the our available data).

## Hello World

_Bayesian inference_ is a framework for estimating parameters and constructing predictions given probability models and data.  _Bayesian data analysis_ is the larger process of building, fitting, and checking probability models.  _Stan_ is an open-source computer program for Bayesian inference and simulation.  Stan can be run from R, Python, Julia, or other scientific/statistical software.  In the examples in this book, we set up data and run Stan from R, but our focus is on Stan, not the R code.

### Getting started {-}

Go to the Stan webpage (http://mc-stan.org) and navigate to users and interfaces.  Instructions for setting up Stan for use within R are here:  http://mc-stan.org/users/interfaces/rstan.html.  Follow all the steps on that page.

### A Stan program for simple linear regression {-}

Our "Hello World" example for R and Stan is a linear regression,
$$y_i=a+bx_i +\mbox{error}_i, \mbox{ for } i=1,\dots,N,$$
with errors independent and normally distributed with mean 0 and standard deviation $\sigma$.

Just one little thing to be careful of: statistical notation, the normal distribution with mean $\mu$ and standard deviation $\sigma$ is written as $N(\mu,\sigma^2)$.  In Stan, we write it as normal(mu, sigma) (_not_ sigma^2).

Here is the full model written in Stan:

```{r}
print_file("stan/simplest-regression.stan")
```

The first block of this program declares the inputs to the model, the second declares the parameters to be estimated, and the third presents the statistical model.
And now we can run it:

### Basic Bayesian workflow {-}

We will perform the following steps which are a key part of our workflow:

1. _Simulate fake data._ Set the sample size $N$, predictor vector $x$, and parameters $a,b,\sigma$, and from that information simulate fake data $y$ from the model above.

2. _Fit the model._ Express the model in Stan, pass the data $N,x,y$ into the program, and estimate the parameters.

3. _Evaluate the fit._  Compare the estimated parameters (or, more fully, the posterior distribution of the parameters) to their true values, which in this simulated-data scenario are known.

We begin by setting up R and Stan, setting it to run in parallel and to save compiled Stan programs in the working directory:

```{r}
library("rstan")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

### Simulating fake data {-}

Then we write the program to simulate fake data:

```{r}
print_file("stan/fake-data.stan")
```

The first part of this program declares all the inputs to the program; the second part simulates the data $y$ using the normal random number generator in Stan.
To run the program, we need to specify the sample size $N$, the regression coefficients $a$ and $b$, the residual standard deviation $\sigma$, and the vector of predictors $x$, which we create in R and put in a list:

```{r}
N <- 100
hello_data <- list(N=N, a=10, b=4, sigma=5, x=runif(N, 0, 10))
```
We then run the Stan model and create the fake data:

```{r, warning=FALSE, results=FALSE}
fake_data <- stan("stan/fake-data.stan", chains=1, iter=1, algorithm="Fixed_param", data=hello_data)
```

We only needed one chain and one iteration as we are just simulating one fake dataset (in this case, a vector $y$ of length 100).  Also, just to know:  the first time you run this on your computer, you'll have to wait 15 seconds or so for the Stan model to compile.  After that, it will save the compiled code in your home directory.

We then extract the simulated data vector and append it to our data list:

```{r}
hello_data$y <- extract_one_draw(fake_data)$y
```

Alternatively we could simulate the fake data in R:

```{r}
N <- 100
a <- 10
b <- 4
sigma <- 5
x <- runif(N, 0, 10)
y <- rnorm(N, a + b*x, sigma)
hello_data <- list(N=N, x=x, y=y)
```

The awkward "N=N, x=x, y=y"  formulation arises because we want to give a name to each item in the list.  It is not necessary that the names of the objects and the names within the list be the same.
But for convenience we often use the same names inside and outside the list, as above.

For this example it was simple enough to fit the fake data in R.  But we wanted to show above how to do it in Stan, as this can be useful for more complicated models.

### Fitting the Stan model {-}

In any case, now that we have the data list, we can use it to estimate the parameters:

```{r, results=FALSE}
fit <- stan("stan/simplest-regression.stan", data = hello_data)
```

Here is the summary of the fitted model:

```{r}
print(fit)
```

Now we go through the output:

* The first few lines summarize the Stan run, with the name of the file, the number of chains and iterations.  In this case, Stan ran the default 4 chains with 1000 warmup iterations followed by 1000 post-warmup iterations, yielding 4000 post-warmup simulation draws in total.

* The left column of the table has the names of parameters, transformed parameters, and generated quantities produced by `model.stan`.  In this case, the parameters are a, b, and sigma; the only transformed parameter is `lp__` (the log-posterior density or target function created by the Stan model); and there are no generated quantities.

* The next column of the table shows the mean (average) of the 4000 draws for each quantity.

* The next column shows the Monte Carlo standard error, which is an estimate of the uncertainty in the mean.

* The next column shows the standard deviation of the draws for each quantity.  As the number of simulation draws increases, mean should approach the posterior mean, se_mean should go to zero, and sd should approach the posterior standard deviation.  For most purposes we can ignore se_mean.

* The next several columns give quantiles of the simulations.

* The next columns gives the effective sample size and $\widehat{R}$. Typically we want $\widehat{R}$ to be less then 1.1 for each row of the table.

In the above output, $\widehat{R}$ is less then 1.1 for all quantities, so the chains seem to have mixed well, and we use the results to summarize the posterior distribution.  We can compare the posterior inferences to the true parameter values (here, $a=2$, $b=3$, and $\sigma=5$).  These true values are roughly within the range of uncertainty of the inferences.

## Bayesian workflow

The first page of _Bayesian Data Analysis_ lists the following three idealized steps:

1. Setting up a full probability model---a joint probability distribution for all observable and unobservable quantities in a problem. The model should be consistent with knowledge about the underlying scientific problem and the data collection process.

2. Conditioning on observed data: calculating and interpreting the appropriate posterior distribution—the conditional probability distribution of the unobserved quantities of ultimate interest, given the observed data.

3. Evaluating the fit of the model and the implications of the resulting posterior distribution: how well does the model fit the data, are the substantive conclusions reasonable, and how sensitive are the results to the modeling assumptions in step 1? In response, one can alter or expand the model and repeat the three steps.

More recently we have been thinking about _workflow_, a general expression which, in addition to the above three steps, also includes the processes of trying out different models and checking computations with fake data.

### Idealized plan for Bayesian case studies {-}

Chapter 2 of this book includes several case studies to give some sense of Bayesian modeling on some fairly simple problems, and Chapter 3 offers a guide to a large number of Stan case studies that are available on the Stan webpage.  Presentation of these examples vary, but the paradigmatic format for a case study would follow these steps:

1.  Applied example to give context

2.  Fake-data simulation, including discussion of reasonable parameter values, in R or Stan

3.  Graph of fake data

4.  Stan program

5.  Fit fake data in Stan; discuss convergence etc and parameter estimates and uncertainties

6.  Graph the fitted model along with the data

7.  Fit real data in Stan

8.  Graph the fit

9.  Model checking

10.  Directions for model expansion

## What is Stan?

Stan is a platform for statistical modeling and high-performance statistical computation.  When you write a Stan program, you're writing C++ code that gives instructions for computing an "objective function."  In this book we will be using Stan for Bayesian inference, and the objective function is interpreted as the logarithm of the posterior density, up to an arbitrary constant.

### Writing a Stan program {-}

A Stan program includes various blocks to declare data and parameters and make transformations, but the heart of a Stan program, where it computes the objective function, is in the model block.  The Stan program above has the following model block:
```
model {
  y ~ normal(a + b * x, sigma);
}
```
In this case, $y$ and $x$ are vectors of length $N$, and the above code is mathematically (but not computationally) equivalent to:
```
model {
  for (n in 1:N){
    y[n] ~ normal(a + b * x[n], sigma);
  }
}
```
Each line inside the loop adds a term to the objective function with the logarithm of the corresponding normal density; thus, $\log(\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{1}{2}(\frac{y_n - (a + bx_n)}{\sigma})^2)) = - \frac{1}{2}\log(2\pi) - \frac{1}{2}\log\sigma - \frac{1}{2}(\frac{y_n - (a + bx_n)}{\sigma})^2$.  For most purposes, we do not care about arbitrary multiplicative constants in the posterior density or, equivalently, arbitrary additive constants in the log-posterior density, so it does not matter if the $- \frac{1}{2}\log(2\pi)$ term is present.  We _do_ need to include $- \frac{1}{2}\log\sigma$, however, because $\sigma$ is a parameter in the model and thus we cannot consider this term as constant.

For reasons that we shall discuss later, the above code is more efficient in vectorized form (without the loop).

The relevant point of the above discussion is that the model block is where the objective function is computing, with distributional statements corresponding to increments to the objective function.  We can make this explicit by rewriting the above model block as:
```
model {
  target += normal_lpdf(y | a + b * x, sigma);
}
```
Or
```
model {
  for (n in 1:N){
    target += y[n] ~ normal_lpdf(y[n] | a + b * x[n], sigma);
  }
}
```
Here, "target" is the objective function, "lpdf" stands for "log probability density function," and the vertical bar is statistics notation for conditioning:  thus, we are adding to the objective function the normal log density function of $y$, given mean $a+bx$ and standard deviation $\sigma$.

Here is a slightly more elaborate version, in which we include $\mbox{normal}(0,1)$ prior distributions for $a$, $b$, and $\sigma$ (actually the prior for $\sigma$ is half-normal as this parameter has been constrained to be positive).  We will talk more about priors in a bit; for here, you can just think of these extra statements as representing additional information that the parameters $a$, $b$, and $\sigma$ are likely to be not too far from 0:
```
model {
  y ~ normal(a + b * x, sigma);
  a ~ normal(0, 1);
  b ~ normal(0, 1);
  sigma ~ normal(0, 1);
}
```
Or, equivalently:
```
model {
  target += normal_lpdf(y | a + b * x, sigma);
  target += normal_lpdf(a | 0, 1);
  target += normal_lpdf(b | 0, 1);
  target += normal_lpdf(sigma | 0, 1);
}
```
Every line in the model block with a tilde (~) corresponds to an augmentation of the target, or objective function.

We can also include lines in the code that do _not_ augment the objective function.  For example:
```
model {
  real a_shifted;
  a_shifted = a + 2*b;  // expected value of y when x=2
  y ~ normal(a + b * x, sigma);
  a_shifted ~ normal(0, 1);
  b ~ normal(0, 1);
  sigma ~ normal(0, 1);
}
```
Here we wanted to assign a prior distribution not to the parameter $a$ but to the shifted parameter $a+2b$.  The above code is executed directly, with an augmentation of "target" for every line with a tilde.

### Interpreting the objective function as the log posterior density {-}

That is, the objective function is interpreted as being the log posterior density of the parameters, plus some arbitrary constant.  Mathematically, if the objective function computed by Stan is $g(\theta,y)$, then the implied posterior density is $p(\theta|y)=\frac{1}{Z(y)}e^{g(\theta,y)}$, where $Z(y)=\int g(\theta,y)d\theta$.  To perform inference using this posterior distribution, is not necessary to actually evaluate the integral $Z$; it is enough to be able to compute $g$.

### Stan's fitting algorithms {-}

As described above, a Stan program can be viewed as instructions for computing an objective function.

When you run a Stan program, it performs optimization or approximation or sampling of this objective function, using one of the algorithms described below.

#### Option 1:  Sampling {-}

Usually when we run Stan we use it to _sample_ from the posterior distribution that is proportional to the exponential of the objective function.  Currently available in Stan are two different sampling algorithms:  Hamiltonian Monte Carlo (HMC) and the no-U-turn sampler (NUTS).  For background on HMC, see Chapter 12 of _Bayesian Data Analysis_.  NUTS is an adaptive version of HMC (for more information, see Chapter ** of this book) and is the algorithm that we use by default when fitting models in Stan.  When running NUTS (or HMC, or any other sampling algorithm), the output of Stan is a list of posterior simulations.

We gave an example earlier, when we typed:

```{r, results=FALSE}
fit <- stan("stan/simplest-regression.stan", data=hello_data)
```

The output of the Stan run, saved in R as the object "fit", contains posterior simulations and also some other information regarding the settings of the fitting algorithm.  Here, for example, we access some simulations:

```{r}
sims_as_matrix <- as.matrix(fit)
print(sims_as_matrix[1:5,])
sims_as_list <- extract(fit)
print(sims_as_list$a[1:5])
```

Each row of the above matrix is a different posterior simulation:  we see the parameters $a$, $b$, and $\sigma$, along with the objective function (or log-posterior density), "lp__".

#### Option 2:  Optimization {-}

The simplest way to run Stan is on optimize setting; it then uses the BFGS algorithm to find (or attempt to find) the maximum of the objective function, and Stan returns the value of the parameters at this estimated mode along with the computed value of the objective function.
Here is an example:

```{r, results=FALSE}
simplest <- stan_model("stan/simplest-regression.stan")
fit_2 <- optimizing(simplest, data=hello_data)
```

In this case we broke the computation into two steps, first compiling and saving the compiled model into the R object "simplest" and then performing the optimizer on this program.  And here is the result:

```{r}
print(fit_2)
```

For this simple model, the values of the parameters at the optimum are close to the posterior median estimates obtained from to the NUTS fit earlier.  We also get the value of the objective function, which has no direct interpretation in this case, and a return code which represents the stability of the optimizer.  (A return code of 0 is good news.)

Interpreting the objective function as the log posterior density, the result of the optimizer is the posterior mode.  If the model has a uniform prior distribution, then this is also the maximum likelihood estimate.

In classical statistics, the maximum likelihood is accompanied by an uncertainty estimate based on the curvature of the log-likelihood function; see Sections 4.1 and 13.3 of _Bayesian Data Analysis_ for a corresponding Bayesian interpretation based on the posterior mode.  There are times when this mode-based approximation makes sense---notably when datasets are so large that full Bayesian computation is too slow to be practical---but usually we fit our Stan models using simulation, so that we get posterior uncertainties directly, with no need for any normal approximation.

#### Option 3:  Distributional approximations {-}

Stan also allows you to fit models using ADVI (autodifferentiated variational inference).  As an approximation to the posterior distribution, ADVI can work better than simple mode-based approximations and it can be much faster for large problems, but currently the way ADVI is implemented in Stan, there are concerns about its convergence.  We have applied ADVI to a few hundred small example models where we can compare to the full posterior distribution:  in many of these examples, ADVI works well, but in some examples, ADVI gives apparent convergence but to the wrong answer that is not a good approximation to the posterior.  Hence, when using ADVI, it is important to do some fake-data simulation to check that the algorithm can recover something close to the underlying model.  For now, it is probably best to think of ADVI as an experimental tool that you should only try for problems that are too large to solve using regular NUTS.

### Iterations and steps {-}

Stan's fitting algorithms are iterative.  The algorithm starts with some initial values for all the parameters (these can be user-specified and fed into the call to Stan, or else Stan will simulate them from a default distribution; see Chapter ** of this book) and then, at each _iteration_, the parameter values are updated.  After enough iterations, the parameter values converge to an estimate of the optimum (if Stan is being set to optimization) or to an estimate of the center of the distribution (if Stan is being set to distributional approximation) or the iterations will wander through the posterior distribution (if Stan is being set to sample).

In the HMC and NUTS algorithms (and recall that NUTS is Stan's default), each iteration includes some number of _steps_.   In each step, Stan computes the gradient of the objective function, which is used in the "leapfrog algoritm" to determine the direction in which the algorithm moves (see Section 12.4 of _Bayesian Data Analysis_ and Chapter ** of this book).  An iteration might have tens or hundreds of steps.  The information from the steps is not saved by Stan; what is returned is the value of the parameters at the end of each iteration.

As a user, you typically don't need to worry about steps or iterations; all that is relevant is that Stan returns posterior simulation draws of the parameters.  But when Stan has convergence problems or when it takes a long time to fit a model, then it can be helpful to understand what is happening under the hood, as often it can be possible to reparameterize or reprogram the model to run more efficiently.

### Adaptation and warmup {-}

The iterative algorithms have _tuning parameters_.  These are not statistical parameters in the model to be estimated; rather, they are settings that need to be adjusted for the algorithms to run efficiently.  The sampling algorithms in Stan have _warmup_ and _production_ stages.  In the warmup stage, the tuning parameters are altered using various heuristics with the goal of efficient movement during the production stages, whose iterations are saved.  In the current default settings, Stan runs for 1000 warmup iterations and 1000 production iterations, but we would like to change these defaults to become more adaptive, running fewer iterations if that is all that is needed, and automatically running more when 2000 iterations are not enough.

### Multiple chains, mixing, R-hat {-}

To have trust in the results of an iterative algorithm, it can be helpful to run it from different starting points and check that the different runs of the algorithm reach the same endpoint.  Each run of the algorithm is called a "chain" because the algorithms can often be described mathematically as Markov chains; hence we speak of _multiple chains_.  By default, when run from R, Stan simulates 4 chains in parallel, which is convenient on many laptop computers which have 4 processors.

For optimization or distributional approximation, we literally want the different chains to converge to the same spot.  For sampling, we want the different chains to trace out the same distribution, which we measure by comparing the simulations from different chains to each other.  For each parameter or quantity of interest saved, Stan reports "R-hat," a numerical measure which is larger than 1 when chains have not mixed well and becomes close to 1 when the chains have mixed.  We typically run Stan for the default number of iterations and, if R-hat is less than 1.1 for all parameters, we just use the simulations to represent the posterior distribution.  If R-hat is greater than 1.1 for any parameters, the algorithm is slow to converge and we might run it longer and then, if mixing remains poor, consider reparameterization of the problem.


### Blocks and declarations {-}

As the language is currently configured, a Stan program is divided into _blocks_:

- Data.  Here you declare all the information that must be supplied for the program to run.  For example, in a regression model, the data would be x, y, and N.  Each data object in a Stan program must be given a type, such as int (integer), real, vector, matrix, etc.  Explanations of all the types are in Chapter ** of this book.

- Transformed data.  These are mathematical operations that are performed once when the Stan program is called.

- Parameters.  These are the unknown quantities that are estimated when the Stan program is run.  Parameters also need to be declared, and they need to be continuous.  You cannot have an integer-valued parameter.  See Chapter ** for further discussion of this point.

- Transformed parameters.  Computations that depend on parameters as well as data, thus must be computed in each step when Stan runs.

- Model.  This is the part of the Stan program where the objective function is computed.  As discussed above, at each step, Stan computes the objective function by starting at zero and then adding to it with each statement that includes "target +=" or "~".

- Generated quantities.  These are computed at the end of each iteration (not each step) and are saved.

### Vectors and arrays {-}

Here is an example of a Stan model with a vector parameter:

```{r}
print_file("stan/vector-regression.stan")
```

To fit this model, we simply reconfigure the data by constructing the matrix of predictors and then run from R:

```{r, results=FALSE}
ones <- rep(1, N)
X <- cbind(ones, x)
K <- 2
data_3 <- list(N=N, K=K, X=X, y=y)
fit_3 <- stan("stan/vector-regression.stan", data=data_3)
```

Here is the result:

```{r}
print(fit_3)
```

And here is what happens if we grab the matrix or list of posterior simulations:

```{r}
sims_as_matrix <- as.matrix(fit_3)
print(sims_as_matrix[1:5,])
sims_as_list <- extract(fit_3)
print(sims_as_list$b[1:5,])
```

The parameter $b$ is a vector, and so the posterior simulations are a 2-dimensional array.  Similarly, if $b$ is a matrix or array of vectors, the posterior simulations will become a 3-dimensional array, and so on.  We shall encounter such parameter structures when fitting hierarchical models.

### Troubleshooting, warnings, etc {-}

Stan gives warnings and also lots of default output.  We should talk about this.

### Stan and other probabilistic programming languages {-}

Programs that perform Bayesian inference are called _probabilistic programming languages_.  Compared to other such languages, Stan is particularly flexible in its expression of models . . .

## Software environment

### Working in R and Stan {-}

In this book, we will work with data and fit Stan models using the rstan package in R, as demonstrated above.  Our focus, though, is on statistical modeling and writing Stan programs, so in most of the book we suppress the R.  All the code is available (see below) so that you can reproduce any of the computations we perform.

### Other options:  Python, Julia, etc. {-}

Stan can also be run from the command line or from other statistical environments such as Python and Julia.  See the Stan webpage and look under interfaces for more information.

### How to use this book:  Github, knitr, etc. {-}

You may be reading this book as an html or pdf file or even as a printed document.  The underlying content lives on the Github page here:  **.  Each chapter of the book is a "knitr file," which means that it can be run in R, most conveniently using Rstudio.  You can also go to the raw knitr docs (again, most conveniently using the editor in Rstudio):  these are the files with .Rmd extensions.  These documents have the text of the book (e.g., the words you are reading now) along with all the R code, some of which is hidden in this html or pdf document that you are reading but is visible in the raw .Rmd documents.

The Stan programs used in this book are all in `.stan` files in this same directory tree.

## Bayes and Stan

Bayesian inference is a general approach for learning about unknown parameters and making predictions about missing or latent data, given observed data and a probability model.  For the theory and practice of Bayesian inference, see our book _Bayesian Data Analysis_.  Or, for a more introductory treatment, the book _Statistical Rethinking: A Bayesian Course with Examples in R and Stan_ by Richard McElreath.  We recommend you read those books along with this one.

Stan is a computer program that performs Bayesian inference on any model with continuous parameters whose log-posterior density can be computed (up to an arbitrary additive constant, as discussed above).

If you want to fit a Bayesian model _not_ using Stan, you can perform computations analytically or by direct simulation for some simple models (see the early chapters of _Bayesian Data Analysis_ for many examples), or write your own customized simulation algorithm (see Part III of _Bayesian Data Analysis_), or use some other general-purpose software.  We like Stan, both for fitting Bayesian models in our applied work, and for teaching the general principles of Bayesian modeling.

### What _can't_ be fit in Stan? {-}

There are several sorts of models that can't be fit, or can't be fit well, using Stan.  Other software has problems with such models too.

- Models with discrete parameters.  Stan can only fit continuous-parameter models.  If you have a model with discrete parameters, you have to fit it using some other approach.  Very simple discrete-parameter models can be fit using direct computation of the posterior distribution; we give two such examples in Section 1.4 of _Bayesian Data Analysis_.  For more complicated examples, we can sometimes average over the discrete parameters analytically; see Chapter ** of this book for general discussion and examples of finite mixture and hidden Markov models.  More generally, posterior distributions for models with discrete unknowns can be explored using various stochastic algorithms, but except in certain special cases these can be very slow to converge:  the challenge is to perform a tour of a discrete space without simply going through all the possible values, which would result in a combinatorical explosion.  Thus, we sometimes say that Stan can't walk through discrete spaces, but no other algorithm can do so effectively either.

In any case, if you want to perform Bayesian inference for a model with discrete unknowns, you need to either average over the discrete variables as described in Chapter **, or fit the model outside of Stan.  Either way, we recommend fake-data simulation to check that the fit can recover the parameter values under reasonable assumptions.

- Models with likelihoods or priors that contain uncomputable normalizing constants.  This comes up sometimes with spatial or network models. We won't discuss these further here; you can see Section 13.10 of _Bayesian Data Analysis_ for a brief general discussion of the problem.

- Models for which the NUTS algorithm mixes very slowly.  This can include continuous models with discrete aspects to their geometry, such as multimodal posterior distributions.  Sometimes we can get these models to run more smoothly by reparameterizing; see Chapter ** of this book for the important example of the use of the non-centered parameterization to avoid the "funnel problem" with hierarchical models.

- Models for which the objective function takes a long time to compute.  This includes some models with differential equations (see Chapter ??) or even simple models, if the size of the data or the number of parameters is large enough.  There are various approaches to managing large and slow computations in Stan, including data subsetting, and posterior approximations, and parallel computing.  For most of this book we focus on small and moderate-sized problems; we discuss big-data strategies in Chapter **.


## Where to find more information about Bayesian data analysis and Stan

Here is a list of resources, roughly in order from most to least formal:

- The Stan Reference Manual:  http://mc-stan.org/users/documentation/index.html which has details on the algorithms and implementations used by Stan, along with all of Stan's functions.

- _Bayesian Data Analysis_ by Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin (third edition, 2014)

- _Statistical Rethinking: A Bayesian Course with Examples in R and Stan_ by McElreath (2015)

- _Regression and Other Stories_ by Gelman, Hill, and Vehtari (forthcoming)

- List of example models translated from Bugs and Arm:  https://github.com/stan-dev/example-models/wiki

- Stan case studies:  http://mc-stan.org/users/documentation/case-studies.html and https://github.com/stan-dev/stancon_talks

- Stan Discourse list:  https://discourse.mc-stan.org


# Prior Distributions and Models for Data


## Prior, likelihood, posterior densities; Bayes as information aggregation

As discussed in the context of the Hello World example in chapter 1, a Stan model is constructed by adding to the objective function or log-posterior density; each line in the model block with "target +=" or a "~" symbol adds a term.  The increments can come in any order, as addition is commutative ($X+Y = Y+X$).  So your Stan model can start with the log-prior and then add the log-likelihood, or the other way around.  Or the two can be interspersed.  The structure of Stan can be thought of as an implementation of the general idea of Bayesian inference as information aggregation:  Prior information, data information, all of it is just information that is fed into the inference engine.

## Example:  apparently duplicate priors

Start with the following simple Stan program:

```
data {
  real y;
}
parameters {
  real theta;
}
model {
  theta ~ normal(0, 1);
  y ~ normal(theta, 1);
}
```

Here, the prior and data happen to provide the same amount of information about $\theta$, and the posterior mean of $\theta$ will fall halfway between the data, $y$, and the prior mean, 0.

Now suppose we add a new line to the model block, apparently duplicating the prior:

```
model {
  theta ~ normal(0, 1);
  theta ~ normal(0, 1);
  y ~ normal(theta, 1);
}
```

This looks weird. We have specified a model for $\theta$ twice.  Does this cause an error in the Stan program?  Does Stan simply ignore the duplicate code?  Does the second "prior" overwrite the first?
Actually, no.  The above model block is legal Stan code, as we can see by replacing each line by its equivalent augmentation of the objective function:

```
model {
  target += normal(theta | 0, 1);
  target += normal(theta | 0, 1);
  target += normal(y | theta, 1);
}
```

Each line adds a piece of information to the log posterior density.  In this simple example, all three lines of code contain the equivalent amount of information---each is a normal density with scale 1---and so the posterior mean of $\theta$ will be the average of the three numbers, 0, 0, and $y$.

Indeed, the above code is equivalent to this:

```
model {
  theta ~ normal(0, 1/sqrt(2));
  y ~ normal(theta, 1);
}
```

We cannot in general do this sort of simplification but it happens that with the normal distribution these computations can be performed analytically, as the product of two normal densities is itself normal.

As a practical matter, we do _not_ recommend code like this:

```
  theta ~ normal(0, 1);
  theta ~ normal(0, 1);
```

as it just looks confusing.  But understanding how it works gives insight into the way that priors and data combine to express information.


## Concentration of the likelihood

For any fixed model, as the sample size increases, the likelihood becomes more informative.  This can be seen, for example, in the mdoels above, where each additional data point adds another term to the likelihood in the implicit vector addition of the "target +=" or "~" statement.  See Chapter 4 of _Bayesian Data Analysis_ for more on this.

## Problems with so-called noninformative priors

Before discussing prior distributions more generally, we share a simple example.

You have a single parameter $\theta$ which we estimate using an experiment which returns an estimate $y$.  For simplicity, assume the estimate is unbiased, normally distributed, and with known standard deviation that happens to equal 1.  Thus, the data model is:
$$
y \sim \mbox{normal}(\theta,1).
$$
Now suppose you perform Bayesian inference using a uniform prior on $\theta$.  Then your posterior distribution is simply (see, for example, chapter 2 of _Bayesian Data Analysis_),
$$
\theta|y \sim \mbox{normal}(y,1).
$$
OK, fine.  Now suppose your estimate happens to be $y=1$.  There are two ways of thinking about this:

* The observed data, 1 standard error away from 0, is completely consistent with a true value of $\theta=0$, or of low values of $\theta$ that could be either positive or negative.  From our usual statistical perspective, we would say that the data are consistent with pure noise, and we cannot learn much from these data alone.

* From the Bayesian posterior distribution, we can compute that $\mbox{Pr}(\theta>0) = 0.84$ (in R, `pnorm(1)`), thus you should be willing to bet with 5-to-1 odds that $\theta$ is positive.

This seems wrong, the idea that something recognizable as pure noise can lead to 5:1 posterior odds.

The problem is coming from the prior distribution. We can see this in two ways. First, just directly, effects near zero are more common than large effects.  

Jakulin et al. (2008) argue that logistic regression coefficients are usually less than 1. So let's try  combining normal(1,1) data with a Cauchy(0,1) prior. It's easy enough to do in Stan:

```
data {
  real y;
}
parameters {
  real theta;
}
model {
  theta ~ cauchy (0, 1);
  y ~ normal(theta, 1);
}
```

If we fit this model supplying data $y=1$, and then from the resulting simulations compute the posterior probability that $\theta > 0$, we get 0.77, that is, roughly a 3:1 posterior probability that the effect is positive.

Just to check that we're not missing anything, let's  re-run using the flat prior. New Stan model:

```
data {
  real y;
}
parameters {
  real theta;
}
model {
  y ~ normal (theta, 1);
}
```
and re-run with the same R code. This time, indeed, 84% of the posterior simulations of $\theta$ are greater than 0.

So far so good. Although one might argue that the posterior probability of 0.77 (from the inference given the unit Cauchy prior) is still too high. Perhaps we want a stronger prior? This sort of discussion is just fine. If you look at your posterior inference and it doesn't make sense to you, this "doesn't make sense" corresponds to additional prior information you haven't included in your analysis.

OK, so that's one way to consider the unreasonableness of a noninformative prior in this setting. It's not so reasonable to believe that effects are equally likely to be any size. They're generally more likely to be near zero.

The other way to see what's going on with this example is to take that flat prior seriously. Suppose theta really could be just about anything---or, to keep things finite, suppose you wanted to assign theta a uniform prior distribution on $[-1000,1000]$, and then you gather enough data to estimate $\theta$ with a standard deviation of 1. Then, a priori, you're nearly certain to gather very very strong information about the sign of $\theta$. To start with, there's a 0.998 chance that your estimate will be more than 2 standard errors away from zero so that your posterior odds about the sign of $\theta$ will be at least 20-to-1. And there's a 0.995 chance that your estimate will be more than 5 standard errors away from zero.

So, in your prior distribution, this particular event---that $y$ is so close to zero that there is uncertainty about $\theta$'s sign---is extremely unlikely. And it would be irrelevant that $y$ is not statistically significantly different from 0.

Modeling can be difficult. In some settings the data are strong and prior information is weak, and it's not really worth the effort to think seriously about what external knowledge we have about the system being studied. Often, though, we do know a lot, and we're interested in various questions where data are sparse, and we could be putting more effort into quantifying our prior distribution.

Upsetting situations---for example, the estimate of $1 \pm 1$ which leads to a seemingly too-strong claim of 5-to-1 odds in favor of a positive effect---are helpful in that they can reveal that we have prior information that we have not yet included in our models.



## Priors {#general-priors.section}

The prior only matters where the likelihood is nonzero (and vice-versa).  One way to think of the prior distribution is as a "regularization" or "soft constraint" on the parameters of the model.  We discuss prior choice more fully on this wiki:  https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations

We consider 5 levels of priors:

- Flat prior;

- Super-vague but proper prior: normal(0, 1e6);

- Weakly informative prior, very weak: normal(0, 10);

- Generic weakly informative prior: normal(0, 1);

- Specific informative prior: normal(0.4, 0.2) or whatever. Sometimes this can be expressed as a scaling followed by a generic prior: theta = 0.4 + 0.2*z; z ~ normal(0, 1);

In Stan, if you don't supply any prior at all, you are implicitly using a flat prior.  In general we don't recommend this, but for many cases in this book, such as the Hello World example above, we use flat priors for simplicity and because we are focuseing on the expression of the data model or likelihood.

Setting up priors goes along with setting up the model.  You want to set up your parameters so they are understandable, and then you will typically have some sense of their possible range, and you can use this to set up priors.  If you have a lot of data, the prior won't matter much, but there are lots of real examples where data are weak and it it is helpful to use an informative prior.

### Background Reading {-}

See @Gelman:2006 for an overview of choices for priors for
scale parameters, @ChungEtAl:2013 for an overview of choices
for scale priors in penalized maximum likelihood estimates, and
@GelmanJakulinPittauEtAl:2008 for a discussion of prior choice
for regression coefficients.

### Improper Uniform Priors {-}

The default in Stan is to provide uniform (or "flat") priors on
parameters over their legal values as determined by their declared
constraints.  A parameter declared without constraints is thus given a
uniform prior on $(-\infty,\infty)$ by default, whereas a scale
parameter declared with a lower bound of zero gets an improper uniform
prior on $(0,\infty)$.  Both of these priors are improper in the sense
that there is no way formulate a density function for them that
integrates to 1 over its support.

Stan allows models to be formulated with improper priors, but in order
for sampling or optimization to work, the data provided must ensure a
proper posterior.  This usually requires a minimum quantity of data,
but can be useful as a starting point for inference and as a baseline
for sensitivity analysis (i.e., considering the effect the prior
has on the posterior).

Uniform priors are specific to the scale on which they are formulated.
For instance, we could give a scale parameter $\sigma > 0$ a uniform
prior on $(0,\infty)$, $q(\sigma) = c$ (we use $q$ because the
"density" is not only unnormalized, but unnormalizable), or we could
work on the log scale and provide $\log \sigma$ a uniform prior on
$(-\infty,\infty)$, $q(\log \sigma) = c$.  These work out to be
different priors on $\sigma$ due to the Jacobian adjustment necessary
for the log transform.

Stan automatically applies the necessary Jacobian adjustment for
variables declared with constraints to ensure a uniform density on the
legal constrained values.  This Jacobian adjustment is turned off when
optimization is being applied in order to produce appropriate maximum
likelihood estimates.

### Proper Uniform Priors: Interval Constraints {-}

It is possible to declare a variable with a proper uniform prior by
imposing both an upper and lower bound on it, for example,

```
real<lower=0.1, upper=2.7> sigma;
```

This will implicitly give `sigma` a $\mathsf{Uniform}(0.1, 2.7)$
prior.

#### Matching Support to Constraints {-}

As with all constraints, it is important that the model
provide support for all legal values of `sigma`.  For example,
the following code constraints `sigma` to be positive, but then
imposes a bounded uniform prior on it.

```
parameters {
  real<lower=0> sigma;
  ...
model {
  // *** bad *** : support narrower than constraint
  sigma ~ uniform(0.1, 2.7);
```

The sampling statement imposes a limited support for `sigma` in
(0.1, 2.7), which is narrower than the support declared in the
constraint, namely $(0, \infty)$.  This can cause the Stan program to
be difficult to initialize, hang during sampling, or devolve to a
random walk.

#### Boundary Estimates {-}

Estimates near boundaries for interval-constrained parameters
typically signal that the prior is not appropriate for the model.  It
can also cause numerical problems with underflow and overflow when
sampling or optimizing.

### "Uninformative" Proper Priors {-}

It is uncommon to see models with priors on regression
coefficients such as $\mathsf{normal}(0,1000)$.^[The practice was common in BUGS and can be seen in most of their examples @LunnEtAl:2012.]

If the prior scale, such as 1000, is several orders of magnitude
larger than the estimated coefficients, then such a prior is
effectively providing no effect whatsoever.

We actively discourage users from using the default scale priors
suggested through the BUGS examples [@LunnEtAl:2012], such as
$$
\sigma^2 \sim \mathsf{InvGamma}(0.001, 0.001).
$$

Such priors concentrate too much probability mass outside of
reasonable posterior values, and unlike the symmetric wide normal
priors, can have the profound effect of skewing posteriors; see
@Gelman:2006 for examples and discussion.

### Truncated Priors {-}

If a variable is declared with a lower bound of zero, then assigning
it a normal prior in a Stan model produces the same effect as
providing a properly truncated half-normal prior.  The truncation at
zero need not be specified as Stan only requires the density up to a
proportion.  So a variable declared with

```
real<lower=0> sigma;
```

and given a prior
```
sigma ~ normal(0, 1000);
```

gives `sigma` a half-normal prior, technically

$$
p(\sigma)
\ = \
\frac{\mathsf{normal}(\sigma | 0, 1000)}
     {1 - \mathsf{NormalCDF}(0 | 0, 1000)}
\ \propto \
\mathsf{normal}(\sigma | 0, 1000),
$$

but Stan is able to avoid the calculation of the normal cumulative
distribution (CDF) function required to normalize the half-normal density.
If either the prior location or scale is a parameter or if the
truncation point is a parameter, the truncation cannot be dropped,
because the normal CDF term will not be a constant.


### Weakly Informative Priors {-}

Typically a researcher will have some knowledge of the scale of the
variables being estimated.  For instance, if we're estimating an
intercept-only model for the mean population height for adult women,
then we know the answer is going to be somewhere in the one to three
meter range.  That gives us information around which to form a weakly
informative prior.

Similarly, a logistic regression with predictors on the standard scale
(roughly zero mean, unit variance) is unlikely to have a
coefficient that's larger than five in absolute value.  In these
cases, it makes sense to provide a weakly informative prior such as
$\mathsf{normal}(0,5)$ for such a coefficient.

Weakly informative priors help control inference computationally and
statistically.  Computationally, a prior increases the curvature
around the volume where the solution is expected to lie, which in turn
guides both gradient-based like L-BFGS and Hamiltonian Monte Carlo
sampling by not allowing them to stray too far from the location of a
surface.  Statistically, a weakly informative prior is more sensible
for a problem like women's mean height, because a  diffuse prior
like $\mathsf{normal}(0,1000)$ will ensure that the vast majority of
the prior probability mass is outside the range of the expected
answer, which can overwhelm the inferences available from a small data
set.

### Bounded Priors {-}

Consider the women's height example again.  One way to formulate a
proper prior is to impose a uniform prior on a bounded scale.  For
example, we could declare the parameter for mean women's height to
have a lower bound of one meter and an upper bound of three meters.
Surely the answer has to lie in that range.

Similarly, it is uncommon to see priors for scale parameters that
impose lower bounds of zero and upper bounds of  large numbers,
such as 10,000.^[This was also a popular strategy in the BUGS example models [@LunnEtAl:2012], which often went one step further and set the lower bounds to a small number like 0.001 to discourage numerical underflow to zero.]

This provides roughly the same problem for estimation as a 
diffuse inverse gamma prior on variance.  We prefer to leave
parameters which are not absolutely physically constrained to float
and provide them informative priors.  In the case of women's height,
such a prior might be $\mathsf{normal}(2,0.5)$ on the scale of meters;
it concentrates 95% of its mass in the interval $(1,3)$, but still
allows values outside of that region.

In cases where bounded priors are used, the posterior fits should be
checked to make sure the parameter is not estimated at or  close
to a boundary.  This will not only cause computational problems, it
indicates a problem with the way the model is formulated.  In such
cases, the interval should be widened to see where the parameter fits
without such constraints, or boundary-avoid priors should be used (see
the [hierarchical priors section](#hierarchical-priors.section).)


### Fat-Tailed Priors and Default Priors {-}

A reasonable alternative if we want to accommodate outliers is to use a
prior that concentrates most of mass around the area where values are
expected to be, but still leaves a lot of mass in its tails.  One choice in such a situation is to use a Cauchy distribution for a
prior, which can concentrate its mass around its median, but has tails
that are so fat that the variance is infinite.

Without specific information, the Cauchy prior can be a reasonable default
parameter choice for regression coefficients
@GelmanJakulinPittauEtAl:2008 and the half-Cauchy (coded
implicitly in Stan) a reasonable default choice for scale parameters
@Gelman:2006.



### Informative Priors {-}

Ideally, there will be substantive information about a problem that
can be included in an even tighter prior than a weakly informative
prior.  This may come from actual prior experiments and thus be the
posterior of other data, it may come from meta-analysis, or it may
come simply by soliciting it from domain experts.  All the goodness of
weakly informative priors applies, only with more strength.

### Conjugacy {-}

Unlike in Gibbs sampling, there is no computational advantage to
providing conjugate priors (i.e., priors that produce posteriors in
the same family) in a Stan program.^[BUGS and JAGS both support conjugate sampling through Gibbs sampling.  JAGS extended the range of conjugacy that could be exploited with its GLM module.  Unlike Stan, both BUGS and JAGS are restricted to conjugate priors for constrained multivariate quantities such as covariance matrices or simplexes.]

Neither the Hamiltonian Monte Carlo samplers or the optimizers make
use of conjugacy, working only on the log density and its derivatives.

