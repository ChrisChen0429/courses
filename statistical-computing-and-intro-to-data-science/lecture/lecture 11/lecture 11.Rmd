---
title: "lecture 11"
author: "Yi Chen(yc3356)"
date: "November 18, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## lecture 11
###Data Transformations
####Selective Access and the apply() Family

**Selective Access**
Goal: Find the rows in a dataframe matching some condition.
1. Use logicals: create a vector of Boolean (logical) values.
2. Use indices: create a vector of index numbers.
```{r}
data(cats, package = "MASS")
head(cats)
# One way to find heart weight for male cats
head(cats$Hwt[cats$Sex=="M"])
head(cats[cats$Sex=="M","Hwt"])

#sample the data
cats.subset <- sample(1:nrow(cats), size = nrow(cats)/2)
head(cats.subset)
new.cats <- cats[cats.subset,]
head(new.cats, 3)

# In both cases, can save and re-use the values.
males <- cats$Sex == "M"
males2 <- cats[males,]

boy.cats.1 <- subset(cats, Sex == "M")
all(males2 == boy.cats.1)

```

```{r}
states <- data.frame(state.x77, Region = state.region)
head(states, 3)
states$Income[states$Region=="South"] 
# or
states[states$Region == "South", "Income"]

```

** apply() family**

Tasks: Don't Use apply()
1. How many states have at least 150 days of frost per year? Which ones are they? (Hint: you should only need one line of code to answer each question.)
2. For each of the 8 numeric variables in states, what is the average? For each of the variables, how many states have values above the average? (Hint: You may want to use colSums() here.)
```{r}
# question one
sum(states$Frost>150)
row.names(states)[states$Frost>150]

# question two
a <- states[,1:8]
b <- colMeans(states[,1:8])
b
for(i in 1:8){
        a[,i]=b[i]
}
colSums(states[,1:8]>a)


# use apply
## question one
apply(states[,1:8],2,mean)


```

```{r}
# Maximum entry in each column
apply(states[,1:8], MARGIN = 2, FUN = max)
apply(states[,1:8], MARGIN = 2, FUN = which.max)
rownames(states)[apply(states[,1:8], MARGIN = 2, FUN = which.max)]
# Summary of each col, get back matrix!
apply(states[,1:5], MARGIN = 2, FUN = summary)

```

```{r}
# Rewrite the books so the Northeast gets less frost
frow <- function (r) {
        val <- as.numeric(r[7])
        return(ifelse(r[9] == "Northeast", 0.5*val, val))
}

frost.fake <- apply(states, 1, frow) # ???????????????????????????
frost.fake
mean(states$Frost[states$Region == "Northeast"])
mean(frost.fake[states$Region == "Northeast"])

```

```{r}
# Goal: find indices of biggest 3 entries of v,
# Return: corresponding elements of names.v
top.3.names = function(v, names.v) {
        names.v[order(v, decreasing=TRUE)[1:3]]
}
# Run the function on each column of states. Note: here
# v is be a column, and names.v is the state names
apply(states[, 1:7], MARGIN = 2, FUN = top.3.names,names.v = rownames(states))

```

**Tasks**
1. How does Frost correlate with the others variables? Write a function cor.v1.v2() that takes two inputs: v1, a numeric
vector; and v2, another numeric vector, whose default value is states[, "Frost"]. Its output should be the correlation of v1 and v2. (Hint: Use cor().)
2. Using apply() and cor.v1.v2(), calculate the correlation between each one of the 8 numeric variables in the states matrix and the Frost variable.
3. Can you do accomplish the above using cor() directly and passing additional arguments to apply()?
```{r}
cor.v1.v2 <- function(v1,v2=states[,'Frost']){
        return(cor(v1,v2))
}

apply(states[,1:8],2,cor.v1.v2)

cor(states[,1:8])

```

```{r}
# Computes leave-one-out means, also called jackknife means.
mean.less.one <- function(i, vec) {
        return(mean(vec[-i]))
}

my.vec <- states[ ,"Frost"]
n <- length(my.vec)
# my.vec is an additional argument to mean.omitting.one
my.vec.jack <- lapply(1:n, FUN = mean.less.one, vec = my.vec)
# It's a list, and here are the first 3 elements
head(my.vec.jack, 3)

```

```{r}

# Let's avg the Frost variable, within in each region
tapply(states[,"Frost"], INDEX = state.region, FUN = mean)

```

```{r}
mapply(rep, 1:4, 4:1)
```

### Re-ordering and Merging Dataframes
```{r}
head(cats, 3)
hwt.order <- order(cats$Hwt) # By increasing heart weight
cats.order <- cats[hwt.order, ] # Reorder rows
head(cats.order, 3)

# Rank vs order vs sort
this.vec <- c(25, 13, 25, 77, 68)
rank(this.vec)
order(this.vec)
this.vec[order(this.vec)]
sort(this.vec,decreasing = TRUE)

```
```{r}
which.min(cats$Hwt) == order(cats$Hwt)[1]


t(cats)[, 1:5]

```

```{r}
setwd("C:/Users/cheny/Desktop/study/statistical computing and intro to data science/lecture/lecture 11")

fha <- read.csv("fha.csv", na.strings = "NA", colClasses = c("character", rep("double", 3)))
nrow(fha)
colnames(fha)
head(fha, 3)


ua <- read.csv("ua.txt", sep = ";")
nrow(ua)
head(ua, 2)

```

Difficulities:
1. 500 cities vs. 4000  areas"
2. fha orders cities by population, ua is alphabetical by name
3. Both have place-names, but those don't always agree
4. Not even common names for the shared columns
```{r}
length(unique(fha$Population)) == nrow(fha)
# no repeat data
ua.pop.top498 = sort(ua$POP, decreasing = TRUE)[1:nrow(fha)]
max(abs(fha$Population - ua.pop.top498))
# one mach one perfectly

```

```{r}
# Order by population
ua.sort <- ua[order(ua$POP, decreasing = TRUE), ]
area <- ua.sort$AREALANDSQMI[1:nrow(fha)]
df1 <- data.frame(fha, area)
# Neaten up names
colnames(df1) <- c("City","Population","Roads","Mileage","Area")
nrow(df1)
head(df1, 3)

```

```{r}
# use merge function
df2 <- merge(x = fha, y = ua, by.x = "Population", by.y = "POP")
nrow(df2)
tail(df2, 2)


df2.1 <- merge(x = fha, y = ua, by.x = "City", by.y = "NAME")
nrow(df2.1)

df2.2 <- merge(x = fha, y = ua, by.x = "City",by.y = "NAME", all.x = TRUE)
nrow(df2.2)

df2.2$City[is.na(df2.2$POP)]

```

```{r}
# Convert 1,000s of miles to miles
df1$Mileage <- 1000 * df1$Mileage
# Plot daily miles per person vs. area
plot(Mileage/Population ~ Area, data = df1, log = "x",xlab = "Miles driven (per person per day)",ylab = "City area (sq. miles)")
# Impressively flat regression line
abline(lm(Mileage/Population ~ Area, data = df1),col = "blue")

```

### Transforming Data
#### z-score transforming
```{r}
head(scale(cats[,-1], center = TRUE, scale = TRUE), 3)

```

#### rank
```{r}
head(cats$Hwt)
head(rank(cats$Hwt))

```

#### Successive di erences
```{r}
x <- c(111,22,423,2615,24,35,12,525,461,102,532,231)
diff(x, lag = 2)

cumsum(x)

cumprod(x)

cummax(x)

cummin(x)

```

**Tasks**
For each of the 8 numeric variables in states, we want to calculate the geometric mean. 
Solve this in two ways:
1. After you transform the data in a clever way, calculate the geometric mean using colMeans(). Hint: think about the
relationship between sums of logs and logs of products.
2. Write a geom.mean() function which takes as input the.vec and returns the geometric mean. Then apply this function to each column of the data.
```{r}
data <- states[,1:8]
data <- log(data)
result1 <- colMeans(data)
result1 <- exp(result1)
result1


geom.mean <- function(vec){return((cumprod(vec)[length(vec)])^(1/nrow(states)))}

apply(states[,1:8],2,geom.mean)

```


#####Split
```{r}
states.by.reg = split(states, f = states$Region)
class(states.by.reg) # The result is a list
names(states.by.reg) # With 4 elements for the 4 regions
class(states.by.reg[[1]]) # Each element is a data frame

```

```{r}
mean.fun <- function(df) {
        apply(df[, 1:8], MARGIN = 2, mean, na.rm = TRUE)
}
lapply(states.by.reg, mean.fun)

```

##### aggregate() 
```{r}
aggregate(states[,1:8], by = list(states$Region), mean)
```

**Tasks**
1. Split the rows of states by division using the split() function, and call the resulting list states.by.div, (having length 9, with one element per division).
2. Display the first 2 rows of each data frame in the list states.by.div.
3. Aggregate your data by Region and Division and summarize the data by finding the mean.
```{r}
#question one
states.by.div <- split(states,f = row.names(states))
#question two
head(states.by.div,2)
#question three
aggregate(states,by = list(states$Region),mean)

```



